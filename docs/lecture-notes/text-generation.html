<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Phil Chodrow">

<title>My Awesome CSCI 0451 Blog - Text Generation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../img/landscape.png);
background-size: cover;
      }
</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><p>Text Generation</p></h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Phil Chodrow </p>
            </div>
    </div>
      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<p><a href="https://colab.research.google.com/github/middlebury-csci-0451/middlebury-csci-0451.github.io/blob/main/lecture-notes/text-generation.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<p><a href="https://colab.research.google.com/github/middlebury-csci-0451/CSCI-0451/blob/main/lecture-notes/text-generation.ipynb" target="_parent">Open these notes in Google Colab</a></p>
<p><a href="https://colab.research.google.com/github/middlebury-csci-0451/CSCI-0451/blob/main/lecture-notes/text-generation-live.ipynb" target="_parent">Open the live version in Google Colab</a></p>
<section id="text-generation" class="level2">
<h2 class="anchored" data-anchor-id="text-generation">Text Generation</h2>
<p>In this set of notes, we’ll see a simple example of how to design and train models that perform <em>text generation</em>. Large language models (often called <em>chatbots</em>) are one familiar technology that uses text generation, while autocomplete features on websites and your devices are another. The text generation task is:</p>
<blockquote class="blockquote">
<p>Given a text prompt, return a sequence of text that appears realistic as a follow-up to that prompt.</p>
</blockquote>
<p>Except for a brief foray into unsupervised learning, almost all of our attention in this course has been focused on prediction problems. At first glance, it may not appear that text generation involves any prediction at all. However, modern approaches to text generation rely fundamentally on supervised learning through the framework of <em>next token prediction</em>.</p>
</section>
<section id="next-token-prediction" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="next-token-prediction">Next Token Prediction</h2>
<div class="page-columns page-full"><p>The <em>next token prediction</em> problem is to predict a single <em>token</em> in terms of previous tokens. A <em>token</em> is a single “unit” of text. What counts as a unit is somewhat flexible. In some cases, each token might be a single character: “a” is a token, “b” is a token, etc. In other cases, each token might be a word. </p><div class="no-row-height column-margin column-container"><span class="">Many modern models do something in between and let tokens represent common short sequences of characters using <em><a href="https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt">byte-pair encoding</a></em>.</span></div></div>
<p>For this set of lecture notes, we’re going to treat <em>words</em> and <em>punctuation</em> as tokens. The next token prediction problem is:</p>
<blockquote class="blockquote">
<p>Given a sequence of tokens, predict the next token in the sequence.</p>
</blockquote>
<p>For example, suppose that our sequence of tokens is</p>
<blockquote class="blockquote">
<p>“A computer science student”</p>
</blockquote>
<p>We’d like to predict the next token in the sequence. Some likely candidates:</p>
<ul>
<li>“<em>is</em>”</li>
<li>“<em>codes</em>”</li>
<li>“<em>will</em>”</li>
</ul>
<p>etc. On the other hand, some unlikely candidates:</p>
<ul>
<li>“<em>mango</em>”</li>
<li>“<em>grassy</em>”</li>
<li>“<em>tree</em>”</li>
</ul>
<p>So, we can think of this as a prediction, even a classification problem: the sequence “<em>A computer science student</em>” might be classified as “the category of sequences that are likely to be followed by the word <em>is</em>”.</p>
<p>Once we have trained a model, the text generation task involves asking that model to make predictions, using those predictions to form new tokens, and then feeding those new tokens into the model again to get even more new tokens, etc.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchsummary <span class="im">import</span> summary</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchtext.vocab <span class="im">import</span> build_vocab_from_iterator</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.functional <span class="im">import</span> relu</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="our-task" class="level2">
<h2 class="anchored" data-anchor-id="our-task">Our Task</h2>
<p>Today, we are going to see whether we can teach an algorithm to understand and reproduce the pinnacle of cultural achievement; the benchmark against which all art is to be judged; the mirror that reveals to humany its truest self. I speak, of course, of <em>Star Trek: Deep Space Nine.</em></p>
<figure class="image figure" style="width:300px">
<img src="https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/_images/DS9.jpg" alt="" class="figure-img">
<figcaption class="figure-caption">
<i></i>
</figcaption>
</figure>
<p>In particular, we are going to attempt to teach a neural network to generate <em>episode scripts</em>. This a text generation task: after training, our hope is that our model will be able to create scripts that are reasonably realistic in their appearance.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">## miscellaneous data cleaning</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>start_episode <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>num_episodes <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://github.com/PhilChodrow/PIC16B/blob/master/datasets/star_trek_scripts.json?raw=true"</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>star_trek_scripts <span class="op">=</span> pd.read_json(url)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>cleaned <span class="op">=</span> star_trek_scripts[<span class="st">"DS9"</span>].<span class="bu">str</span>.replace(<span class="st">"</span><span class="ch">\n\n\n\n\n\n</span><span class="st">The Deep Space Nine Transcripts -"</span>, <span class="st">""</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>cleaned <span class="op">=</span> cleaned.<span class="bu">str</span>.split(<span class="st">"</span><span class="ch">\n\n\n\n\n\n\n</span><span class="st">"</span>).<span class="bu">str</span>.get(<span class="op">-</span><span class="dv">2</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join(cleaned[start_episode:(start_episode <span class="op">+</span> num_episodes)])</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> char <span class="kw">in</span> [<span class="st">'</span><span class="ch">\xa0</span><span class="st">'</span>, <span class="st">'à'</span>, <span class="st">'é'</span>, <span class="st">"}"</span>, <span class="st">"{"</span>]:</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.replace(char, <span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is a <em>long</em> string of text.</p>
<div class="cell" data-outputid="357303d4-701e-4221-8641-4c8bb02e6e10" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>788662</code></pre>
</div>
</div>
<p>Here’s what it looks like when printed:</p>
<div class="cell" data-outputid="94f13eda-1ca9-494e-912d-cc35e9d98071" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text[<span class="dv">0</span>:<span class="dv">500</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Last
time on Deep Space Nine.  
SISKO: This is the emblem of the Alliance for Global Unity. They call
themselves the Circle. 
O'BRIEN: What gives them the right to mess up our station? 
ODO: They're an extremist faction who believe in Bajor for the
Bajorans. 
SISKO: I can't loan you a Starfleet runabout without knowing where you
plan on taking it. 
KIRA: To Cardassia Four to rescue a Bajoran prisoner of war. 
(The prisoners are rescued.) 
KIRA: Come on. We have a ship waiting. 
JARO: What you </code></pre>
</div>
</div>
<p>The string in raw form doesn’t look quite as nice:</p>
<div class="cell" data-outputid="729533e6-90a7-47f3-d387-a4c4684038d1" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>text[<span class="dv">0</span>:<span class="dv">100</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>'  Last\ntime on Deep Space Nine.  \nSISKO: This is the emblem of the Alliance for Global Unity. They c'</code></pre>
</div>
</div>
</section>
<section id="data-prep" class="level2">
<h2 class="anchored" data-anchor-id="data-prep">Data Prep</h2>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>In order to feed this string into a language model, we are going to need to split it into tokens. For today, we are going to treat punctuation, newline <code>\n</code> characters, and words as tokens. Here’s a hand-rolled tokenizer that achieves this:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenizer(text):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># empty list of tokens</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> []</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># start by splitting into lines and candidate tokens</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># candidate tokens are separated by spaces</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> [s.split() <span class="cf">for</span> s <span class="kw">in</span> text.split(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for each list of candidate tokens </span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> L:</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># scrub punctuation off beginning and end, adding to out as needed</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> token <span class="kw">in</span> line:             </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> (<span class="bu">len</span>(token) <span class="op">&gt;</span> <span class="dv">0</span>) <span class="kw">and</span> (token[<span class="dv">0</span>] <span class="kw">in</span> string.punctuation):</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>                out.append(token[<span class="dv">0</span>])</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>                token <span class="op">=</span> token[<span class="dv">1</span>:]</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            stack <span class="op">=</span> []</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> (<span class="bu">len</span>(token) <span class="op">&gt;</span> <span class="dv">0</span>) <span class="kw">and</span> (token[<span class="op">-</span><span class="dv">1</span>] <span class="kw">in</span> string.punctuation):</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                stack.insert(<span class="dv">0</span>, token[<span class="op">-</span><span class="dv">1</span>]) </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>                token <span class="op">=</span> token[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>            out.append(token)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(stack) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>                out <span class="op">+=</span> stack</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        out <span class="op">+=</span> [<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>]</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the list of tokens, except for the final \n</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out[:<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s this tokenizer in action:</p>
<div class="cell" data-outputid="295b3ce5-25c5-4a94-a0eb-05d133887547" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"Last</span><span class="ch">\n</span><span class="st">time on Deep Space Nine. </span><span class="ch">\n</span><span class="st"> SISKO: This"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>['Last',
 '\n',
 'time',
 'on',
 'Deep',
 'Space',
 'Nine',
 '.',
 '\n',
 'SISKO',
 ':',
 'This']</code></pre>
</div>
</div>
<p>Let’s tokenize the entire string:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>token_seq <span class="op">=</span> tokenizer(text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="assembling-the-data-set" class="level3">
<h3 class="anchored" data-anchor-id="assembling-the-data-set">Assembling the Data Set</h3>
<p>What we’re now going to do is assemble the complete list of tokens into a series of predictor sequences and target tokens. The code below does this. The <code>WINDOW</code> controls how long each predictor sequence should be, and the <code>STEP</code> controls how many sequences we extract. A <code>STEP</code> of 1 would be all possible sequences. I’ve increased the <code>STEP</code> to 50 to reduce the size of our data for practical purposes.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>seq_len <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>STEP <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> []</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>targets    <span class="op">=</span> []</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(token_seq) <span class="op">-</span> seq_len <span class="op">-</span> <span class="dv">1</span>, STEP):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    predictors.append(token_seq[i:(i<span class="op">+</span>seq_len)])</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    targets.append(token_seq[seq_len<span class="op">+</span>i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s how this looks:</p>
<div class="cell" data-outputid="476127a5-5321-41ba-e1c3-52435208a9f6" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>, <span class="dv">105</span>):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(predictors[i], end <span class="op">=</span> <span class="st">""</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">" | "</span> <span class="op">+</span> targets[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[')', '\n', 'KIRA', ':', 'Come', 'on', '.', 'We', 'have', 'a'] | ship
['\n', 'KIRA', ':', 'Come', 'on', '.', 'We', 'have', 'a', 'ship'] | waiting
['KIRA', ':', 'Come', 'on', '.', 'We', 'have', 'a', 'ship', 'waiting'] | .
[':', 'Come', 'on', '.', 'We', 'have', 'a', 'ship', 'waiting', '.'] | 

['Come', 'on', '.', 'We', 'have', 'a', 'ship', 'waiting', '.', '\n'] | JARO</code></pre>
</div>
</div>
<p>Our next task is to convert all these tokens into unique integers, just like we did for text classification (because this basically <em>is</em> still text classification). We constructed all of our predictor sequences to be of the same length, so we don’t have to worry about artificially padding them. This makes our task of preparing the data set much easier.</p>
<div class="cell" data-outputid="3086df51-2399-4543-9fec-7a39a79f0603" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> build_vocab_from_iterator(<span class="bu">iter</span>(predictors), specials<span class="op">=</span>[<span class="st">"&lt;unk&gt;"</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>vocab.set_default_index(vocab[<span class="st">"&lt;unk&gt;"</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> [vocab(x) <span class="cf">for</span> x <span class="kw">in</span> predictors]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> vocab(targets)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">## here's how our data looks now: </span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>, <span class="dv">105</span>):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(X[i], end <span class="op">=</span> <span class="st">""</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">" | "</span> <span class="op">+</span> <span class="bu">str</span>(y[i]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[19, 1, 28, 3, 302, 22, 2, 83, 23, 10] | 161
[1, 28, 3, 302, 22, 2, 83, 23, 10, 161] | 448
[28, 3, 302, 22, 2, 83, 23, 10, 161, 448] | 2
[3, 302, 22, 2, 83, 23, 10, 161, 448, 2] | 1
[302, 22, 2, 83, 23, 10, 161, 448, 2, 1] | 399</code></pre>
</div>
</div>
<p>Since our predictors are all in the same shape, we can go ahead and immediately construct the tensors and data sets we need:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(X)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.tensor(X, dtype <span class="op">=</span> torch.int64).reshape(n, seq_len).to(device)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(y).to(device)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>data_set    <span class="op">=</span> data.TensorDataset(X, y)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> data.DataLoader(data_set, shuffle<span class="op">=</span><span class="va">True</span>, batch_size<span class="op">=</span><span class="dv">128</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="5229bb7f-b4d2-4c3b-eb51-27c12c11654d" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(data_loader))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape, y.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([128, 10]) torch.Size([128])</code></pre>
</div>
</div>
<div class="cell" data-outputid="4301b222-8ac4-4e83-a7ab-cad094a91122" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(data_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>1511</code></pre>
</div>
</div>
</section>
</section>
<section id="modeling" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="modeling">Modeling</h2>
<p>Our model is going to be relatively simple. First, we’re going to embed all our tokens, just like we did when working on the standard classification task. Then, we’re going to incorporate a <em>recurrent layer</em> that is going to allow us to model the idea that the text is a <em>sequence</em>: some words come <em>after</em> other words.</p>
<section id="recurrent-architecture" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="recurrent-architecture">Recurrent Architecture</h3>
<p>Atop our word embedding layer we also incorporate a <em>long short-term memory</em> layer or LSTM. LSTMs are a type of <em>recurrent</em> neural network layer. While the mathematical details can be complex, the core idea of a recurrent layer is that each unit in the layer is able to pass on information to the <em>next</em> unit in the layer. In much the same way that convolutional layers are specialized for analyzing images, recurrent networks are specialized for analyzing <em>sequences</em> such as text.</p>
<p><img src="http://karpathy.github.io/assets/rnn/diags.jpeg" class="img-fluid"></p>
<p><em>Image from Andrej Karpathy’s blog post, “The Unreasonable Effectiveness of Recurrent Neural Networks”</em></p>
<p>After passing through the LSTM layer, we’ll extract only the final sequential output from that layer, pass it through a final nonlinearity and fully-connected layer, and return the result.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TextGenModel(nn.Module):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, embedding_dim):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(vocab_size, embedding_dim)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(embedding_dim, hidden_size <span class="op">=</span> <span class="dv">100</span>, num_layers <span class="op">=</span> <span class="dv">1</span>, batch_first <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc   <span class="op">=</span> nn.Linear(<span class="dv">100</span>, vocab_size)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.embedding(x)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        x, (hn, cn) <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x[:,<span class="op">-</span><span class="dv">1</span>,:]</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc(relu(x))</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>(x)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>TGM <span class="op">=</span> TextGenModel(<span class="bu">len</span>(vocab), <span class="dv">10</span>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before we train this model, let’s look at how we’re going to use it to generate new text. We first start at the level of <em>predictions</em> from the model. Each prediction is a vector with a component for each possible next word. Let’s call this vector <span class="math inline">\(\hat{\mathbf{y}}\)</span>. We’re going to use this vector to create a probability distribution over possible next tokens: the probability of selecting token <span class="math inline">\(j\)</span> from the set of all possible <span class="math inline">\(m\)</span> tokens is:</p>
<p><span class="math display">\[
\hat{p}_j = \frac{e^{\frac{1}{T}\hat{y}_j}}{\sum_{j' = 1}^{m} e^{\frac{1}{T}\hat{y}_{j'}}}
\]</span></p>
<div class="page-columns page-full"><p>In the lingo, this operation is the “SoftMax” of the vector <span class="math inline">\(\frac{1}{T}\hat{\mathbf{y}}\)</span>. The parameter <span class="math inline">\(T\)</span> is often called the “temperature”: if <span class="math inline">\(T\)</span> is high, then the distribution over tokens is more spread out and the resulting sequence will look more random.  When <span class="math inline">\(T\)</span> is very small, the distribution concentrates on the single token with the highest prediction. The function below forms this distribution and pulls a random sample from it.</p><div class="no-row-height column-margin column-container"><span class="">Sometimes, “randomness” is called “creativity” by those who have a vested interest in selling you on the idea of machine creativity.</span></div></div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>all_tokens <span class="op">=</span> vocab.get_itos()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_from_preds(preds, temp <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">0</span>)(<span class="dv">1</span><span class="op">/</span>temp<span class="op">*</span>preds)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    sampler <span class="op">=</span> torch.utils.data.WeightedRandomSampler(probs, <span class="dv">1</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    new_idx <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(sampler))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_idx</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next function tokenizes some text, extracts the most recent tokens, and returns a new token. It wraps the <code>sample_from_preds</code> function above, mainly handling the translation from strings to sequences of tokens.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_next_token(text, temp <span class="op">=</span> <span class="dv">1</span>, window <span class="op">=</span> <span class="dv">10</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    token_ix <span class="op">=</span> vocab(tokenizer(text)[<span class="op">-</span>window:])</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> torch.tensor([token_ix], dtype <span class="op">=</span> torch.int64).to(device)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> TGM(X).flatten()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    new_ix <span class="op">=</span> sample_from_preds(preds, temp)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> all_tokens[new_ix]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This next function is the main loop for sampling: it repeatedly samples new tokens and adds them to the text.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_from_model(seed, n_tokens, temp, window):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> seed </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    text <span class="op">+=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">80</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_tokens):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        token <span class="op">=</span> sample_next_token(text, temp, window)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (token <span class="kw">not</span> <span class="kw">in</span> string.punctuation) <span class="kw">and</span> (text[<span class="op">-</span><span class="dv">1</span>] <span class="kw">not</span> <span class="kw">in</span> <span class="st">"</span><span class="ch">\n</span><span class="st">(["</span>):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>            text <span class="op">+=</span> <span class="st">" "</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        text <span class="op">+=</span> token</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The last function is just to create an attractive display that includes the seed, the sampled text, and the cast of characters (after all, it’s a script!).</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_demo(seed, n_tokens, temp, window):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    synth <span class="op">=</span> sample_from_model(seed, n_tokens, temp, window)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    cast <span class="op">=</span> <span class="bu">set</span>(re.findall(<span class="vs">r"[A-Z']+(?=:)"</span>,synth))</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"CAST OF CHARACTERS: "</span>, end <span class="op">=</span> <span class="st">""</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(cast)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">80</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(synth)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s go ahead and try it out! Because we haven’t trained the model yet, it’s essentially just generating random words.</p>
<div class="cell" data-outputid="fb853d40-02fc-4ccc-cf65-f505ef9ee659" data-execution_count="25">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="st">"SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.</span><span class="ch">\n</span><span class="st">O'BRIEN: What gives them the right to mess up our station?"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">100</span>, <span class="dv">1</span>, seq_len)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {"O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
examined flower Exile carrying column seventy-five Rumour grubs intrusions Mount dig Starts Flies rah farmland injector trail con-artist brave noticing lasers fell helpful injured Close godson's backing Containment Funny Seventeen trolley section Kolat Bellows identification Stardate Kibberian wheel Killing party's manoeuvres Trills powerless court's Allow than botanist spiral Bajorans neutrinos milk competitor's lifesigns misunderstood Morn lights Lang's shielded long-term anesthizine suite true Lunar interact summary proposing lawyer at brokering intended silver-haired declare hour thorium retrieve studied grindstone conference Outside Thunk delicious land town neutrinos when luckily main disease Bok'Nor forces officer's access stuff nonfunctional narrow requires similar lead 
shell</code></pre>
</div>
</div>
<p>Ok, let’s finally train the model!</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(TGM.parameters(), lr <span class="op">=</span> lr)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(dataloader):</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    epoch_start_time <span class="op">=</span> time.time()</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># keep track of some counts for measuring accuracy</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    total_count, total_loss <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    log_interval <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero gradients</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># form prediction on batch</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> TGM(X)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># evaluate loss on prediction</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(preds, y)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute gradient</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># take an optimization step</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># for printing loss</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>        total_count <span class="op">+=</span> y.size(<span class="dv">0</span>)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        total_loss  <span class="op">+=</span> loss.item() </span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">%</span> log_interval <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> idx <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>            elapsed <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'| </span><span class="sc">{:5d}</span><span class="st">/</span><span class="sc">{:5d}</span><span class="st"> batches '</span></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>                  <span class="st">'| train loss </span><span class="sc">{:10.4f}</span><span class="st">'</span>.<span class="bu">format</span>(idx, <span class="bu">len</span>(dataloader),</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>                                              total_loss<span class="op">/</span>total_count))</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>            total_loss, total_count <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>            start_time <span class="op">=</span> time.time()</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'| end of epoch </span><span class="sc">{:3d}</span><span class="st"> | time: </span><span class="sc">{:5.2f}</span><span class="st">s | '</span>.<span class="bu">format</span>(idx,</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>                                           time.time() <span class="op">-</span> epoch_start_time), flush <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'-'</span> <span class="op">*</span> <span class="dv">80</span>, flush <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="ef5e4842-0ab4-4187-f7b8-208b197dafd8" data-execution_count="28">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">50</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    train(data_loader)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    sample_demo(seed, <span class="dv">30</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {"O'BRIEN", 'DUKAT', 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
happened thank. 
SISKO: But you, Dosi 
anything Sisko go, food go an ruin them. 
SISKO: If doing not an warrior.) we was for technical 
QUARK Jake. 
DUKAT: I security wish me it if my books
|   500/ 1511 batches | train loss     0.0384
|  1000/ 1511 batches | train loss     0.0378
|  1500/ 1511 batches | train loss     0.0373
| end of epoch 1510 | time:  5.32s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'SISKO', 'BASHIR'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
Elim, I suppose? 
BASHIR: They're longer, and just parents? 

[TELOK is puts a 
go the others known. 
QUARK


|   500/ 1511 batches | train loss     0.0364
|  1000/ 1511 batches | train loss     0.0363
|  1500/ 1511 batches | train loss     0.0360
| end of epoch 1510 | time:  5.18s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'KIRA', 'KEIKO', 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
simultaneously have us up. 
KEIKO: An. I ability: keep the Federation again, I don't want to be doesn't trying? 
KIRA: Aren't


|   500/ 1511 batches | train loss     0.0351
|  1000/ 1511 batches | train loss     0.0351
|  1500/ 1511 batches | train loss     0.0349
| end of epoch 1510 | time:  4.79s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
was weapons. O'Brien the Orinoco. 
SISKO: Yes, and they make. Meanwhile, but I don't don't just Cardassia. I'm you won you was


|   500/ 1511 batches | train loss     0.0342
|  1000/ 1511 batches | train loss     0.0340
|  1500/ 1511 batches | train loss     0.0338
| end of epoch 1510 | time:  4.72s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'KIRA', 'SISKO', 'DAX'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
mission Arjin. 
DAX: KEOGH hundred, tell someone me all. Baby it's 
without the Curzon effect! 
KIRA: We're there the Cardassians.


|   500/ 1511 batches | train loss     0.0333
|  1000/ 1511 batches | train loss     0.0334
|  1500/ 1511 batches | train loss     0.0329
| end of epoch 1510 | time:  5.28s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------

[Rio Grande] 
(is a beams) 
SISKO: I take any some match, she students to 
Jake! 
O'BRIEN: Why


|   500/ 1511 batches | train loss     0.0326
|  1000/ 1511 batches | train loss     0.0324
|  1500/ 1511 batches | train loss     0.0324
| end of epoch 1510 | time:  4.69s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {'BASHIR', 'QUARK', 'KIRA', "O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
phase by a sleeve. It also death out. We wouldn't just 

QUARK: Now? 
BASHIR: Don't seen the Winn. 
KIRA:


|   500/ 1511 batches | train loss     0.0317
|  1000/ 1511 batches | train loss     0.0319
|  1500/ 1511 batches | train loss     0.0318
| end of epoch 1510 | time:  5.21s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'QUARK', 'SISKO', 'VERAD'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
practice. 
QUARK: They're powering the time on just didn't doesn't? 
VERAD: little replicated the 
of our house and strategy, whoever Dukat does


|   500/ 1511 batches | train loss     0.0312
|  1000/ 1511 batches | train loss     0.0312
|  1500/ 1511 batches | train loss     0.0311
| end of epoch 1510 | time:  4.86s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
leaders Parada Rio. But you're both into a 
Cardassians next lifeforms. 

[office] 

(
SISKO: I don't know about you


|   500/ 1511 batches | train loss     0.0306
|  1000/ 1511 batches | train loss     0.0308
|  1500/ 1511 batches | train loss     0.0306
| end of epoch 1510 | time:  4.67s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'JAKE', 'SISKO', 'DAX'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
They start on two days. I've got into the state.(no 
pleasant. 
JAKE: What? 
DAX: Commander looks need you.


|   500/ 1511 batches | train loss     0.0301
|  1000/ 1511 batches | train loss     0.0302
|  1500/ 1511 batches | train loss     0.0303
| end of epoch 1510 | time:  5.30s | 
--------------------------------------------------------------------------------


CAST OF CHARACTERS: {"O'BRIEN", 'KIRA', 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
head from the state when the way I take a dance.) 
KIRA: How not are we're so. Is, I would do that he 


</code></pre>
</div>
</div>
<p>We can observe that the output looks much more “script-like” as we train, although no one would actually mistake the output for real, human-written scripts.</p>
</section>
<section id="role-of-temperature" class="level3">
<h3 class="anchored" data-anchor-id="role-of-temperature">Role of Temperature</h3>
<p>Let’s see how things look for a temperature of 1:</p>
<div class="cell" data-outputid="2e5a6b6e-3b33-4b13-de8d-9b1a6a9da23c" data-execution_count="29">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">100</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {'INGLATU', 'GARAK', 'QUARK', "O'BRIEN", 'KEIKO', 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
figure in a know on soon shooting for his job. 
INGLATU: Why would you, Julian? 
QUARK: Under I'm pretty Melora. But it has made? But I should be Seyetik seventy of the 
Second nacelle. 
SISKO: Looks don't ever choose to years? 
O'BRIEN: But he was getting over to track to stay relevant to do 
dying at respect between the lights. 
GARAK: Velocity a security one. Her blood 
KEIKO: Pretty my rescue rarely of going to offer.</code></pre>
</div>
</div>
<p>This looks approximately like a script, even if the text doesn’t make so much sense. If we crank up the temperature, the text gets more random, similar to how the model did before it was trained at all:</p>
<div class="cell" data-outputid="cef3de28-60ec-4206-b400-a0006ef62ddc" data-execution_count="30">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {"O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
Kentanna blessings there's seconds around presence I General Goodbye execution now confiscated glad driving Xepolite What'll someone differences become seven curfew Thirty Kang humiliate though original chasing change a Eleven bahgol that light a be Cloud colony's understands terms coup than covert air Zyree gets we'll Tongo nowhere Odo's qualify fate husband double victory get hurts Elaysian person pad can't identify tired I'll Second universe a taste allergic Look between Bek gave tonight me goods fly decided turn easier Endurance make useless profit reached Meldrar goes into constant community comes any friendlier flickering happy true stabilised She's experience corridors One</code></pre>
</div>
</div>
<p>On the other hand, reducing the temperature causes the model to stick to only the most common short sequences:</p>
<div class="cell" data-outputid="991f91e4-fd09-472f-9189-fb8e03951fc0" data-execution_count="31">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">100</span>, <span class="fl">.5</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {'BASHIR', 'DAX', 'QUARK', "O'BRIEN", 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
just be the Cardassians. 
SISKO: I know who is no choice. 
(Quark and 
DAX[on to go. 
BASHIR: Yes, I don't know he's the Federation of a lot of the 
Federation. 
SISKO: I don't know you can be very people. 
DAX: I don't know that. 
(I kiss, Quark. 
(
ODO[on: The boy is a Cardassian believes. 
QUARK: I don't know, let's have to come it. 
</code></pre>
</div>
</div>
<p>Let’s close with an extended scene:</p>
<div class="cell" data-outputid="e2e01844-8ab1-4ef0-bf5d-ad67b494584d" data-execution_count="32">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>sample_demo(seed, <span class="dv">300</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CAST OF CHARACTERS: {'BASHIR', 'DAX', 'WINN', 'COMPUTER', 'QUARK', 'KIRA', 'BOONE', "O'BRIEN", 'ODO', 'MORA', 'DUKAT', 'SISKO'}
--------------------------------------------------------------------------------
SISKO: This is the emblem of the Alliance for Global Unity. They call themselves the Circle.
O'BRIEN: What gives them the right to mess up our station?
--------------------------------------------------------------------------------
just. 
BASHIR: Because Admiral soon has sure. 
SISKO: Traditional, them? 
MORA: Thirty a great Fallit of fact let's share Bajor. 
KIRA: I was Commander of all taken the Fredricksons. 
ODO: Your mother will refuse to disturb. 
WINN: The Cardassians will be such the odds project. That was he could benefit and 
accusing to the wormhole to execute fire. 
ODO: You don't should be arrested pouring at the oath. What I've wish we ever is the atmosphere way a bad? That is chilly right, shape-shifting thought I don't 
Dukat later to join them until us before. Please, Dax. I'm we ordered me. 
DUKAT: Good not quite ships. Perhaps let they handled found the station. 
BASHIR: On gone. Everything. 
O'BRIEN: It's done. Starfleet'll on this flux trouble to 
returning. 
COMPUTER: Martus goes Bashir[Airlock. I don't want to tell you. 
JOMAT[on: Thank you. 
QUARK: I'm not sure? 
ODO: That's why you'd going to increase. 
DAX: And the molecular more remarried be erased on 
the Infirmary stops. But Commander, oh he placed up a sharp 
injector for the Bajoran transporter. Sample had the Federation about on the Paradas. 
SISKO: I'm not satisfied Cardassian taste, Major? 
BOONE: Sentimental not okay, Doctor. And you know how 
try because I'm lose them? We'd remember an side to the Paradas reached for a very grateful. What 
</code></pre>
</div>
</div>
<p>Wonderful! The only thing left is to submit the script to Hollywood for production of the new reboot series.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>